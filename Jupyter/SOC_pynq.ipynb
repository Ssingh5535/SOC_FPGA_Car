{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay, MMIO, lib\n",
    "from pynq.lib.video import VideoMode\n",
    "from PIL import Image\n",
    "import cffi\n",
    "from time import sleep\n",
    "import os\n",
    "import numpy as np\n",
    "os.environ[\"OPENCV_LOG_LEVEL\"]=\"SILENT\"\n",
    "# initialize camera from OpenCV\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before starting this piece of code be sure that SW0 on board is in OFF position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "overlay = Overlay(\"design_1_wrapper.xsa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to manage the convolution filter mapped on FPGA. It provides method to modify \"on fly\" the kernel (7x7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution_Filter:\n",
    "    def __init__(self, overlay, base_address=0x43C10000, address_range=0x10000, address_offset=0x40):\n",
    "        self.base_address = base_address\n",
    "        self.address_range = address_range\n",
    "        self.address_offset = address_offset\n",
    "        self.offset = 0x04\n",
    "        self.mmio = MMIO(base_address, address_range)\n",
    "        self.conv = overlay.filter.convolution_filter\n",
    "        \n",
    "    def update_filter(self, fil):\n",
    "        if(len(fil) != 51):\n",
    "            print(\"La lunghezza del filtro deve essere di 51 elementi\")\n",
    "            \n",
    "        address = self.address_offset\n",
    "        data = 0x00000000\n",
    "        bits_shift = 0\n",
    "        counter = 0\n",
    "        \n",
    "        for el in fil:\n",
    "            if(bits_shift >= 32):\n",
    "                self.mmio.write(address, data)\n",
    "                data = 0x00000000\n",
    "                bits_shift = 0\n",
    "                address = address + self.offset\n",
    "            \n",
    "            counter += 1\n",
    "            data = data | (el << bits_shift)\n",
    "            bits_shift += 8\n",
    "            if(counter >= 51):\n",
    "                self.mmio.write(address, data)\n",
    "    \n",
    "    def print_filter(self):\n",
    "        f1 = self.conv.mmio.array.view('int8')[0x40:0x71]\n",
    "        f2 = self.conv.mmio.array.view('int8')[0x71:0x73]\n",
    "        \n",
    "        print(f1.reshape((7,7)))\n",
    "        print(f2.reshape((1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to manage OV7670 sensor. It provides basic methods to write and read sensor's registers and a basic setup that works quite well in our configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OV7670:\n",
    "    def __init__(self, iic):\n",
    "        self.OV7670_SLAVE_ADDRESS = 0x21\n",
    "        \n",
    "        _ffi = cffi.FFI()\n",
    "        self.tx_buf = _ffi.new(\"unsigned char [32]\")\n",
    "        self.rx_buf = _ffi.new(\"unsigned char [32]\")\n",
    "        \n",
    "        self.iic = iic\n",
    "\n",
    "    def write_register(self, reg, data):\n",
    "        self.tx_buf[0] = reg\n",
    "        self.tx_buf[1] = data\n",
    "\n",
    "        self.iic.send(self.OV7670_SLAVE_ADDRESS, self.tx_buf, 2, 0)\n",
    "\n",
    "    def read_register(self, reg):\n",
    "        self.tx_buf[0] = reg\n",
    "\n",
    "        self.iic.send(self.OV7670_SLAVE_ADDRESS, self.tx_buf, 1, 0)\n",
    "        self.iic.receive(self.OV7670_SLAVE_ADDRESS, self.rx_buf, 1, 0)\n",
    "\n",
    "        return self.rx_buf[0]\n",
    "\n",
    "    def default_setup(self):\n",
    "        self.write_register(0x12, 0x80)\n",
    "        sleep(1)\n",
    "        self.write_register(0x0E, 0x01)\n",
    "        self.write_register(0x0F, 0x4B)\n",
    "        self.write_register(0x16, 0x02)\n",
    "        self.write_register(0x1E, 0x07)\n",
    "        self.write_register(0x21, 0x02)\n",
    "        self.write_register(0x22, 0x91)\n",
    "        self.write_register(0x29, 0x07)\n",
    "        self.write_register(0x33, 0x0B)\n",
    "        self.write_register(0x35, 0x0B)\n",
    "        self.write_register(0x37, 0x1D)\n",
    "        self.write_register(0x38, 0x01)\n",
    "        self.write_register(0x0C, 0x00) \n",
    "        self.write_register(0x3C, 0x78)\n",
    "        self.write_register(0x4D, 0x40)\n",
    "        self.write_register(0x4E, 0x20)\n",
    "        self.write_register(0x74, 0x10)\n",
    "        self.write_register(0x8D, 0x4F)\n",
    "        self.write_register(0x8E, 0x00)\n",
    "        self.write_register(0x8F, 0x00)\n",
    "        self.write_register(0x90, 0x00)\n",
    "        self.write_register(0x91, 0x00)\n",
    "        self.write_register(0x96, 0x00)\n",
    "        self.write_register(0x9A, 0x00)\n",
    "        self.write_register(0xB0, 0x84)\n",
    "        self.write_register(0xB1, 0x04)\n",
    "        self.write_register(0xB2, 0x0E)\n",
    "        self.write_register(0xB3, 0x82)\n",
    "        self.write_register(0xB8, 0x0A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage example of OV7670 class to program sensor with a basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iic = overlay.axi_iic\n",
    "ov7670 = OV7670(iic)\n",
    "ov7670.default_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before exexuting this piece of code set SW0 on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage example of convolution filter class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpen_filter = [\n",
    "    1, 0, 0, 0, 0, 0, 0,\n",
    "    0, 1, 0, 0, 0, 0, 0,\n",
    "    0, 0, 1, 0, 0, 0, 0,\n",
    "    0, 0, 0, 1, 0, 0, 0,\n",
    "    0, 0, 0, 0, 1, 0, 0,\n",
    "    0, 0, 0, 0, 0, 1, 0,\n",
    "    0, 0, 0, 0, 0, 0, 1,\n",
    "    7, 0]\n",
    "\n",
    "neutral_filter = [\n",
    "    0, 0, 0, 0, 0, 0, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0,\n",
    "    0, 0, 0, 1, 0, 0, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0,\n",
    "    0, 0, 0, 0, 0, 0, 0,\n",
    "    1, 0]\n",
    "\n",
    "vertical_filter = [\n",
    "\t-1, -2, -4, 0, 4, 2, 1,\n",
    "\t-1, -2, -4, 0, 4, 2, 1,\n",
    "\t-2, -4, -6, 0, 6, 4, 2,\n",
    "\t-4, -6, -8, 0, 8, 6, 4,\n",
    "\t-2, -4, -6, 0, 6, 4, 2,\n",
    "\t-1, -2, -4, 0, 4, 2, 1,\n",
    "\t-1, -2, -4, 0, 4, 2, 1,\n",
    "    120, 127]\n",
    "\n",
    "fil = Convolution_Filter(overlay)\n",
    "fil.update_filter(sharpen_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration of vdma with a resolution of 800x600 and 24 bit for each pixel\n",
    "vdma = overlay.VDMA.axi_vdma\n",
    "\n",
    "vdma.readchannel.reset()\n",
    "vdma.readchannel.mode = VideoMode(800, 600, 24)\n",
    "vdma.readchannel.start()\n",
    "\n",
    "vdma.writechannel.reset()\n",
    "vdma.writechannel.mode = VideoMode(800, 600, 24)\n",
    "vdma.writechannel.start()\n",
    "\n",
    "frame = vdma.readchannel.readframe() # Needed because first frame is always black\n",
    "\n",
    "vdma.readchannel.tie(vdma.writechannel) # Connect input directly to output of vdma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frame = vdma.readchannel.readframe()\n",
    "\n",
    "\n",
    "#img = cv2.GaussianBlur(frame,(5,5),0)\n",
    "#edge = cv2.Canny(frame, 100, 200)\n",
    "\n",
    "#edge = cv2.Canny(img, 50, 150)\n",
    "#edge_rgb = cv2.cvtColor(edge, cv2.COLOR_GRAY2RGB)\n",
    "#img2 = Image.fromarray(edge_rgb, 'RGB')\n",
    "#display(img2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lane_markings(image):\n",
    "    lane_check = 0\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to smooth the image\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform edge detection using Canny\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "\n",
    "    # Define region of interest (lower part of the image with a limited distance from the bottom)\n",
    "    height, width = edges.shape\n",
    "    mask = np.zeros_like(edges)\n",
    "    \n",
    "    # Define the distance from the bottom of the image to disregard lane markings\n",
    "    distance_from_bottom = 100  # Adjust this value as needed\n",
    "    \n",
    "    polygon = np.array([[(0, height - distance_from_bottom), (width, height - distance_from_bottom), \n",
    "                         (width, height), (0, height)]], np.int32)\n",
    "    cv2.fillPoly(mask, polygon, 255)\n",
    "    masked_edges = cv2.bitwise_and(edges, mask)\n",
    "\n",
    "    # Detect lines using Hough transform\n",
    "    lines = cv2.HoughLinesP(masked_edges, rho=1, theta=np.pi/180, threshold=15, minLineLength=10, maxLineGap=20)\n",
    "\n",
    "    # Create a blank image with the same size as the original image\n",
    "    lane_markings_image = np.zeros_like(image)\n",
    "\n",
    "    # Draw detected lines on the lower part of the image\n",
    "    if lines is not None:\n",
    "        lane_check = 1\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(lane_markings_image, (x1, y1), (x2, y2), (0, 255, 0), 5)\n",
    "    \n",
    "    return lane_check, lane_markings_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_stop_sign(image):\n",
    "    stop_check=0\n",
    "    # Convert image to grayscale\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 30, 100)\n",
    "\n",
    "    # Find contours in the edge-detected image\n",
    "    contours, _ = cv2.findContours(edges.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Iterate through contours to find potential stop signs\n",
    "    stop_sign_image = np.zeros_like(image)\n",
    "    for contour in contours:\n",
    "        # Approximate the contour to a polygon\n",
    "        approx = cv2.approxPolyDP(contour, 0.03 * cv2.arcLength(contour, True), True)\n",
    "\n",
    "        # Check if the polygon has 8 vertices (indicating a stop sign)\n",
    "        if len(approx) == 8:\n",
    "            # Calculate the bounding box for the polygon\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "\n",
    "            # Calculate the aspect ratio of the bounding box\n",
    "            aspect_ratio = w / float(h)\n",
    "\n",
    "            # Check if the aspect ratio is approximately 1 (indicating a square)\n",
    "            if 0.8 <= aspect_ratio <= 1.2:\n",
    "                # Check if the contour area is within a reasonable range\n",
    "                contour_area = cv2.contourArea(contour)\n",
    "                if 2000 <= contour_area <= 5000:  # Adjust area thresholds as needed\n",
    "                    # Draw a green rectangle around the detected stop sign\n",
    "                    cv2.rectangle(stop_sign_image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "                    stop_check=1\n",
    "\n",
    "    return stop_sign_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_address_motor1 = 0x40000000\n",
    "base_address_motor2 = 0x40001000\n",
    "address_range = 0x1000\n",
    "duty_cycle_addr_offset = 0x04\n",
    "pulse_cycle_addr_offset = 0x08\n",
    "duty_cycle_data_motor1 = 15000\n",
    "pulse_cycle_data_motor1 = 10000\n",
    "duty_cycle_data_motor2 = 15000\n",
    "pulse_cycle_data_motor2 = 5000\n",
    "\n",
    "# Motor 1\n",
    "mmio_motor1 = MMIO(base_address_motor1, address_range)\n",
    "mmio_motor1.write(duty_cycle_addr_offset, duty_cycle_data_motor1)\n",
    "mmio_motor1.write(pulse_cycle_addr_offset, pulse_cycle_data_motor1)\n",
    "pulse_cycle_read_motor1 = mmio_motor1.read(pulse_cycle_addr_offset)\n",
    "\n",
    "# Motor 2\n",
    "mmio_motor2 = MMIO(base_address_motor2, address_range)\n",
    "mmio_motor2.write(duty_cycle_addr_offset, duty_cycle_data_motor2)\n",
    "mmio_motor2.write(pulse_cycle_addr_offset, pulse_cycle_data_motor2)\n",
    "pulse_cycle_read_motor2 = mmio_motor2.read(pulse_cycle_addr_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_address2=0x40001000\n",
    "\n",
    "\n",
    "duty_cycle_data2 = 10000\n",
    "pulse_cycle_data2 = 5000\n",
    "#iic.mmio = MMIO(base_address2, address_range)\n",
    "#iic.mmio.write(duty_cycle_addr_offset, duty_cycle_data2)\n",
    "#iic.mmio.write(pulse_cycle_addr_offset, pulse_cycle_data2)\n",
    "#iic.mmio.read(pulse_cycle_addr_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "while True:\n",
    "    frame = vdma.readchannel.readframe()\n",
    "    image = frame\n",
    "    lane_check, lane_markings_result = detect_lane_markings(image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " #Detect stop sign\n",
    "#stop_sign_result = detect_stop_sign(image)\n",
    "\n",
    "#if(stop_sign_result == 1):\n",
    " #   iic.mmio.write(duty_cycle_addr_offset, 0)\n",
    "  #  iic.mmio.write(pulse_cycle_addr_offset, pulse_cycle_data)\n",
    "   # iic.mmio.write(duty_cycle_addr_offset, 0)\n",
    "    #iic.mmio.write(pulse_cycle_addr_offset, pulse_cycle_data2)\n",
    "if (lane_check == 1):\n",
    "    mmio_motor1.write(duty_cycle_addr_offset, duty_cycle_data_motor1)\n",
    "    mmio_motor1.write(pulse_cycle_addr_offset, pulse_cycle_data_motor1)\n",
    "    mmio_motor2.write(duty_cycle_addr_offset, duty_cycle_data_motor2)\n",
    "    mmio_motor2.write(pulse_cycle_addr_offset, pulse_cycle_data_motor2)\n",
    "    pass\n",
    "else:\n",
    "    mmio_motor1.write(duty_cycle_addr_offset, 0)\n",
    "    mmio_motor1.write(pulse_cycle_addr_offset, 0)\n",
    "    mmio_motor2.write(duty_cycle_addr_offset, 0)\n",
    "    mmio_motor2.write(pulse_cycle_addr_offset, 0)\n",
    "    pass\n",
    "\n",
    "#overlay_image = cv2.addWeighted(image, 1, lane_markings_result, 0.5, 0)\n",
    "#overlay_image = cv2.addWeighted(overlay_image, 1, stop_sign_result, 0.5, 0)\n",
    "\n",
    "# Display results\n",
    "#img2 = Image.fromarray(overlay_image, 'RGB')\n",
    "#display(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
